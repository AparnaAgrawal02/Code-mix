{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from nltk.util import ngrams\n",
    "import random\n",
    "import inltk\n",
    "# from inltk.inltk import setup\n",
    "# from inltk.inltk import tokenize as tokenize_hi\n",
    "from indicnlp.tokenize import indic_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset opus100 (/home/shreya/Shreya/College/Sem6/NLP/Code-mix/temp/../data/OPUS/opus100/en-hi/0.0.0/256f3196b69901fb0c79810ef468e2c4ed84fbd563719920b1ff1fdc750f7704)\n"
     ]
    }
   ],
   "source": [
    "opus = datasets.load_dataset('opus100', 'en-hi', split='train', cache_dir='../data/OPUS/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset:  534319\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of dataset: \", len(opus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry in OPUS: {'translation': {'en': 'Other, Private Use', 'hi': 'अन्य, निज़ी उपयोग'}}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Entry in OPUS: {opus[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixDataset(Dataset):\n",
    "    def __init__(self, opus_data) :\n",
    "        self.tokenizer_en = get_tokenizer('basic_english')\n",
    "        # self.tokenizer_hi = get_tokenizer('indic_tokenize', language='hi')\n",
    "        self.opus_data = opus_data\n",
    " \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.opus_data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        en, hi =  self.opus_data[idx]['translation']['en'], self.opus_data[idx]['translation']['hi']\n",
    "        en = self.tokenizer_en(en)\n",
    "        hi = indic_tokenize.trivial_tokenize_indic(hi)\n",
    "        bi_grams_en = ngrams(en, 2)\n",
    "        bi_grams_hi = ngrams(hi, 2)\n",
    "        bi_en, bi_hi = [], []\n",
    "        for w1, w2 in bi_grams_en :\n",
    "            bi_en.append(w1 + '_' + w2)\n",
    "        for w1, w2 in bi_grams_hi :\n",
    "            bi_hi.append(w1 + '_' + w2)\n",
    "        ret = en + hi + bi_en + bi_hi\n",
    "        print(ret)\n",
    "        random.shuffle(ret)\n",
    "        print(ret)\n",
    "        return ret\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = MixDataset(opus)\n",
    "dl = DataLoader(ds, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = 'अन्य, निज़ी उपयोग'\n",
    "# indic_tokenize.trivial_tokenize_indic(text)\n",
    "\n",
    "# st = \"Other, Private Use\"\n",
    "# tokenizer = get_tokenizer('basic_english')\n",
    "# st_tok = tokenizer(st)\n",
    "# bigrams = ngrams(st_tok, 2)\n",
    "# list(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt = [['अन्य', 'निज़ी', 'उपयोग'], ['Other', 'Private', 'Use']]\n",
    "model = Word2Vec(sentences=dl, vector_size=100, window=5, min_count=1, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282331604, 301995180)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(dl, total_examples=len(opus), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model.wv\n",
    "word_vectors.save(\"../models/word2vec.wordvectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wvs(path='../models/word2vec.wordvectors'):\n",
    "    return KeyedVectors.load(path, mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.',),\n",
       " (',',),\n",
       " ('the',),\n",
       " ('(',),\n",
       " (')',),\n",
       " ('है',),\n",
       " ('और',),\n",
       " ('and',),\n",
       " ('के',),\n",
       " ('to',)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "word_vectors.index_to_key[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('and',)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.41233677,  0.1988115 ,  0.6786996 , -0.180497  ,  0.82508934,\n",
       "        0.7571229 , -1.4232038 , -1.0387919 , -0.20736161,  0.24093974,\n",
       "        0.14588594, -1.1100832 , -1.5298404 , -0.39773425,  0.48344457,\n",
       "       -0.01060129,  0.706726  ,  0.7970445 ,  0.25171965, -0.57115126,\n",
       "       -0.1276712 , -0.34812385, -0.41411856, -0.07656819, -0.6181094 ,\n",
       "        0.83155215,  0.10770226, -0.45943722,  0.6202324 ,  0.4555967 ,\n",
       "        0.91622734,  0.9224759 , -1.0649984 , -0.02858173,  0.3213145 ,\n",
       "       -0.32913533, -0.48386213, -0.43237954,  0.89069587, -0.2109292 ,\n",
       "        1.2732015 ,  0.423429  , -0.26262724,  0.49468172, -0.45935556,\n",
       "        0.14522399,  0.14959668,  0.4862668 , -1.5445775 ,  0.96105987,\n",
       "       -0.15001087, -0.29731387,  0.58272845,  0.68863237, -0.56848514,\n",
       "        0.64961565,  0.2711853 , -0.13970982,  0.10464289,  1.2039775 ,\n",
       "        0.83498794, -1.077584  ,  0.08991605,  0.11904134,  0.07783502,\n",
       "       -0.44455525, -1.334287  ,  0.6559434 , -0.9875546 , -0.39596426,\n",
       "        0.36295918,  0.3501109 , -0.00419346,  0.4249153 ,  0.13258561,\n",
       "       -0.503979  , -0.25042927,  1.3596509 ,  0.3474675 , -1.0856895 ,\n",
       "        0.12921919, -0.8894675 , -0.23944798, -0.8833109 ,  0.01932753,\n",
       "        0.0658797 ,  0.5792745 ,  1.1674265 ,  1.3853651 , -0.2472804 ,\n",
       "       -0.06031454,  0.6981572 ,  0.5758416 ,  0.5238405 , -0.24279171,\n",
       "        0.46725368, -0.21128383, -0.01361194,  0.44280988, -0.64913255],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(word_vectors.index_to_key[7])\n",
    "word_vectors.get_vector(word_vectors.index_to_key[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between ('and',) and ('और',) is 0.9570193886756897\n",
      "Similarity between ('और',) and ('fire',) is 0.2974220812320709\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "simi = cosine_similarity([word_vectors.get_vector(word_vectors.index_to_key[7])], [word_vectors.get_vector(word_vectors.index_to_key[6])])[0, 0]\n",
    "print(f'Similarity between {word_vectors.index_to_key[7]} and {word_vectors.index_to_key[6]} is {simi}')\n",
    "\n",
    "simi2 = cosine_similarity([word_vectors.get_vector(word_vectors.index_to_key[6])], [word_vectors.get_vector(word_vectors.index_to_key[547])])[0, 0]\n",
    "print(f'Similarity between {word_vectors.index_to_key[6]} and {word_vectors.index_to_key[547]} is {simi2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most similar words to 'और' :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('और',), 1.0),\n",
       " ((',_and',), 0.9642396569252014),\n",
       " (('and',), 0.9570194482803345),\n",
       " (('._and',), 0.8048928380012512),\n",
       " (('है_और',), 0.7780988812446594),\n",
       " (('and_the',), 0.7698213458061218),\n",
       " ((')_और',), 0.6910834908485413),\n",
       " (('and_to',), 0.682357907295227),\n",
       " (('who',), 0.6722629070281982),\n",
       " (('भी',), 0.6722161173820496)]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_similar(word, topn=10):\n",
    "    return word_vectors.most_similar(word, topn=topn)\n",
    "\n",
    "print(\"10 most similar words to '\" + word_vectors.index_to_key[6][0] + \"' :\")\n",
    "most_similar(word_vectors.get_vector(word_vectors.index_to_key[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most similar words to 'of' :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('of',), 1.0),\n",
       " (('of_the',), 0.9338359236717224),\n",
       " (('the',), 0.879870593547821),\n",
       " (('की',), 0.7434549927711487),\n",
       " (('से',), 0.7245144844055176),\n",
       " (('का',), 0.7084817886352539),\n",
       " (('में_से',), 0.6923059821128845),\n",
       " (('के',), 0.6758306622505188),\n",
       " (('._the',), 0.6551926732063293),\n",
       " (('and',), 0.6516838073730469)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"10 most similar words to '\" + word_vectors.index_to_key[10][0] + \"' :\")\n",
    "most_similar(word_vectors.get_vector(word_vectors.index_to_key[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_cmsentence(en_sentence, word_vectors, threshold=0.3) :\n",
    "    tokenizer_en = get_tokenizer('basic_english')\n",
    "    sent_en =  tokenizer_en(en_sentence)\n",
    "    sent_cm = []\n",
    "    for i in range(len(sent_en)) :\n",
    "        sent_en[i] = most_similar(sent_en[i])[0][0]\n",
    "        replace = random.random() < threshold\n",
    "        if not replace :\n",
    "            sent_cm.append(sent_en[i])\n",
    "        else: \n",
    "            sent_cm.append(most_similar(sent_en[i])[1][0])\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-3.9.7-kernel",
   "language": "python",
   "name": "gen-3.9.7-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
